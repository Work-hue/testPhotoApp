TASK 0

In this task, we created an array of patient structures to keep track of all patient data.
Each module loaded consisted of "all_data" and "all_labels" vectors. These vectors were
stored in the patient structure. Next, the test and training data/label sets were created for
each patient and appended.

TASK 1.1A

The following are the prior probabilities of H1 and H0 respectively for each patient.

P(H1)=2.651779e-02 			 P(H0)=9.734822e-01
P(H1)=1.634684e-02 			 P(H0)=9.836532e-01
P(H1)=2.094972e-03 			 P(H0)=9.979050e-01
P(H1)=2.492522e-03 			 P(H0)=9.975075e-01
P(H1)=1.046025e-03 			 P(H0)=9.989540e-01
P(H1)=2.176966e-02 			 P(H0)=9.782303e-01
P(H1)=1.710297e-02 			 P(H0)=9.828970e-01
P(H1)=7.790368e-03 			 P(H0)=9.922096e-01
P(H1)=2.176966e-02 			 P(H0)=9.782303e-01

TASK 1.1B

For this task, we constructed the likelihood matrices for each of the seven features
for each patient. This information can be seen in the patients structure. For each patient,
there exists a 1x7 cell called "mats".

TASK 1.1C

When the code runs, 9 figures will be presented. These figures summarize our results as required.

TASK 1.1D

For this task, we constructed the ML and MAP vectors for each patient. These vectors
were appended to each patient structure in the patient array.

TASK 1.1E

For this task, we constructed the 9x7 HT_table_array. Each index into the array is an Fx5 array,
where F is total number of distinct values a particular feature can take.

TASK 1.2

For this task, we constructed the 9x7 Error_table_array. Each index into the array is an 2x3 array.
This smaller array contains the following information: P(False Alarm), P(Missed Detection),
and P(Error). These values are presented in reference to both ML and MAP rules.

TASK 2.1

Patients 6 and 9 have the same data.

Patients 9 and 6 have the same data.

The correlation matrix is stored in the correlation_matrix variable. As one can see in the data structure, apart
from the datasets of the same patients correlating with themselves, we can also see that there are datasets of different
patients that have exactly the same data. These patients are patients 6 and 9. This redundancy is problematic and
to improve our data overall we can choose to eliminate either patients data.

TASK 2.2

For this task, we implemented two ways to select the top two features. The first way was to find
the top two features that had the lowest min(ML error, MAP error) value. This method is expected to work because
intuitively, a feature is good if it has the lowest error using the MAP or ML decision rules. 
The second way was to find the top two features that had the closest correlation to the golden alarms.
It is a good method because intuitively, a feature has a strong influence on the actual result if it is 
strongly correlated with the golden labels.

We found that the top two features for the three patients we chose (1,2,3) are:

Patient 1: 1 	 3
Patient 2: 1 	 3
Patient 3: 2 	 4

We attempted to conclude a better pair of features by experimenting with metrics 3 and 4. After doing a majority vote
using metrics 1 and 2, we wanted to verify the pair of features we obtained using metric 3s feature correlation.
When taking the minimum correlation between pairs of features, we noticed that the pairs we got differed from the pairs obtained
we obtained earlier. From this point, we concluded that there was no evidence that justified which pair to choose from the pool.

We also attempted to use metric 4 to create a new feature consisting of a weighted sum of the original features.
We calculated the weights of each feature based on its accuracy in MAP decision rule. The weights are stored in patient(i).weights
variable. However, we did not make use of the weights to find our top two choices of features, because we decided that there is no
convenient way to test on the new feature created.

 
